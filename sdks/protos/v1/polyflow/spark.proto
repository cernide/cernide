/**
 * Copyright 2018-2020 Polyaxon, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
*/

syntax = "proto3";

package v1;

import "google/protobuf/struct.proto";

import "v1/polyflow/environment.proto";
import "v1/polyflow/init.proto";
import "v1/polyflow/k8s.proto";

// Spark replica defintion
message SparkReplica {
    // Number of replicas
    int32 replicas = 1;

    // Optional environment section
    Environment environment = 2;

    // Optional init connections section
    repeated Init init = 3;

    // Optional sidecars section
    repeated Container sidecars = 4;

    // Optional container to run
    Container container = 5;
}

// Spark specification
message Spark {
    // Kind of runtime, should be equal to "spark"
    string kind = 1;

    // Optional connections section
    repeated string connections = 2;

    // Volumes is a list of volumes that can be mounted.
    repeated Volume volumes = 3;

    enum Type {
        java = 0;
        scala = 1;
        python = 2;
        r = 3;
    }

    // Type tells the type of the Spark application.
    Type type = 4;

    // Spark version is the version of Spark the application uses.
    string spark_version = 5;

    // Spark version is the version of Spark the application uses.
    string python_version = 6;


    enum DeployMode {
        cluster = 0;
        client = 1;
        in_cluster_client = 2;
    }
    // Mode is the deployment mode of the Spark application.
    DeployMode deploy_mode = 7;

    // MainClass is the fully-qualified main class of the Spark application.
    // This only applies to Java/Scala Spark applications.
    string main_class = 8;

    // MainFile is the path to a bundled JAR, Python, or R file of the application.
    string main_application_file = 9;

    // Arguments is a list of arguments to be passed to the application.
    repeated string arguments = 10;

    // HadoopConf carries user-specified Hadoop configuration properties as they would use the  the "--conf" option
	// in spark-submit.  The SparkApplication controller automatically adds prefix "spark.hadoop." to Hadoop
	// configuration properties.
    map<string, string> hadoop_conf = 11;

    // HadoopConf carries user-specified Hadoop configuration properties as they would use the  the "--conf" option
	// in spark-submit.  The SparkApplication controller automatically adds prefix "spark.hadoop." to Hadoop
	// configuration properties.
    map<string, string> spark_conf = 12;

    // SparkConfigMap carries the name of the ConfigMap containing Spark configuration files such as log4j.properties.
	// The controller will add environment variable SPARK_CONF_DIR to the path where the ConfigMap is mounted to.
    string spark_config_map = 13;

	// HadoopConfigMap carries the name of the ConfigMap containing Hadoop configuration files such as core-site.xml.
	// The controller will add environment variable HADOOP_CONF_DIR to the path where the ConfigMap is mounted to.
	string hadoop_config_map = 14;

    // Optional spark executor definition
    SparkReplica executor = 15;

    // Optional spark driver definition
    SparkReplica driver = 16;
}
